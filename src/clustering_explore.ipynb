{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfect_match(v1,v2,k):\n",
    "    if(len(v1)!=len(v2)):\n",
    "        return 0\n",
    "    delta = abs(v1[0] - v2[0])\n",
    "    for i in range(len(v1)):\n",
    "        if(abs(v1[i]-v2[i])-delta > k):\n",
    "            #print(delta, v1[i],v2[i])\n",
    "            return 0\n",
    "    return 1\n",
    "\n",
    "def perfect_align_clustering(phrases_vec,k):\n",
    "    mp = {}\n",
    "    remap = {}\n",
    "    id = 0\n",
    "    phrases = []\n",
    "    for phrase, vec in phrases_vec.items():\n",
    "        if(len(vec) > 1):#phrase appearing only one time is trievally perfectly align with any other one-time phrase and discard them \n",
    "            phrases.append(phrase)\n",
    "\n",
    "    for i in range(len(phrases)):\n",
    "        pi = phrases[i]\n",
    "        vi = phrases_vec[pi]\n",
    "        if(pi not in mp):\n",
    "            mp[pi] = id\n",
    "            remap[id] = [pi]\n",
    "            id += 1\n",
    "        else:\n",
    "            continue\n",
    "        for j in range(i+1, len(phrases)):\n",
    "            pj = phrases[j]\n",
    "            vj = phrases_vec[pj]\n",
    "\n",
    "            #optimization: pj in mp denotes that pj must be at least perfectly match with one phrase before pi, but pi is not in mp\n",
    "            #so pi and pj must be not perfectly aligned, and thus skip comparison \n",
    "            if(pj in mp):\n",
    "                continue\n",
    "\n",
    "            if(perfect_match(vi,vj,k) == 1):\n",
    "                mp[pj] = id-1\n",
    "                remap[id-1].append(pj)\n",
    "    \n",
    "    return mp, remap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def read_dict(file):\n",
    "    print(file)\n",
    "    with open(file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data \n",
    "\n",
    "def read_file(file):\n",
    "    data = []\n",
    "    with open(file, 'r') as file:\n",
    "        # Iterate over each line in the file\n",
    "        for line in file:\n",
    "            # Print the line (you can replace this with other processing logic)\n",
    "            data.append(line.strip())\n",
    "    return data\n",
    "\n",
    "def get_extracted_path(path):\n",
    "    path = path.replace('raw','extracted')\n",
    "    path = path.replace('.pdf','.txt')\n",
    "    return path\n",
    "\n",
    "def get_relative_location_path(extracted_path):\n",
    "    path = extracted_path[:-4] + '_relative_location.csv'\n",
    "    return path\n",
    "\n",
    "def get_root_path():\n",
    "    current_path = os.path.abspath(os.path.dirname(__file__))\n",
    "    parent_path = os.path.abspath(os.path.join(current_path, os.pardir))\n",
    "    #print(\"Parent path:\", parent_path)\n",
    "    return parent_path\n",
    "\n",
    "def get_key_path(extracted_path):\n",
    "    path = extracted_path.replace('extracted','truths/key_truth')\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yiminglin/Documents/Codebase/Pdf_reverse/data/extracted/certification/CT/DecertifiedOfficersRev_9622 Emilie Munson_relative_location.csv\n"
     ]
    }
   ],
   "source": [
    "root_path = '/Users/yiminglin/Documents/Codebase/Pdf_reverse'\n",
    "tested_paths = []\n",
    "tested_paths.append(root_path + '/data/raw/complaints & use of force/Champaign IL Police Complaints/Investigations_Redacted.pdf')\n",
    "tested_paths.append(root_path + '/data/raw/complaints & use of force/UIUC PD Use of Force/22-274.releasable.pdf')\n",
    "tested_paths.append(root_path + '/data/raw/certification/CT/DecertifiedOfficersRev_9622 Emilie Munson.pdf')\n",
    "tested_paths.append(root_path + '/data/raw/certification/IA/Active_Employment.pdf')\n",
    "tested_paths.append(root_path + '/data/raw/certification/MT/RptEmpRstrDetail Active.pdf')\n",
    "tested_paths.append(root_path + '/data/raw/certification/VT/Invisible Institue Report.pdf')\n",
    "\n",
    "tested_id = 2 #starting from 0\n",
    "\n",
    "path = tested_paths[tested_id]\n",
    "extracted_path = get_extracted_path(path)\n",
    "out_path = get_relative_location_path(extracted_path)\n",
    "phrases = read_dict(out_path)\n",
    "mp, remap = perfect_align_clustering(phrases,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 45]\n",
      "[43, 48]\n"
     ]
    }
   ],
   "source": [
    "print(phrases['11/18/2021'])\n",
    "print(phrases['Bridgeport Police Department'])\n",
    "print(phrases['Bridgeport Police Department'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import key \n",
    "import importlib\n",
    "\n",
    "importlib.reload(key)\n",
    "s1 = [8, 112, 236, 351, 451, 552]\n",
    "s2 = [4, 108, 232, 347, 447, 548]\n",
    "\n",
    "key.perfect_match(s2,s1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['Officer Detail Reports #A-12', 'University of Illinois Police Department', 'Case Number', 'Date', 'Time', 'Assist', 'Agency', 'Information Taken From', 'Crime/ Incident', 'Status', 'Completed', 'Incident Reviewed By', 'Date Reviewed', 'Drugs/Alcohol', 'Location', 'K-9', 'Crisis Intervention Related', 'Type Premises', 'District', 'Recorded On Camera', 'Type Situation', 'Reason Force Used', 'Officer Injured', 'Danger Factors', 'Final Disposition', 'Verbal De-Escalation Attempted', '1']\n",
      "1 ['Page 1 of 27', 'Page 2 of 27', '3/19/2021', 'Physical Resistance', 'EH Control - Physical Restraint', 'Osterholt, Drew L.', 'Jones, Kent R.', 'Page 6 of 27', '3/29/2021', 'Page 7 of 27']\n",
      "4 ['SCTF', 'Snow, Ryan S.', 'incident.', 'Firearm', 'UPD', 'Wooded Area', 'Arrested/Lodged', 'Unknown', 'Germany, Karl', 'Page 4 of 27', 'Released / No Action', 'Page 5 of 27', 'Shooting Suspect']\n",
      "10 ['Body Camera']\n",
      "11 ['Fled Scene', 'Fleeing', 'Page 3 of 27']\n",
      "13 ['Notes']\n",
      "14 ['Subject #', 'DOB', 'Gender', 'Male', 'Race', 'HGT', '/', 'WGT', 'Under The Influence', 'Address', 'Level Of Resistance', 'Subject Armed With', 'Force Used', 'Force Location', 'Arrested', 'Arrested For', 'Arrest ID', 'Injured', 'Medical Aid']\n",
      "16 ['N/A']\n",
      "21 ['Officer', 'Action Taken', 'Action Taken Useful', 'CIT', 'Disciplinary Action', 'Included On Alert']\n",
      "22 ['Firearm - Pointed At Subject']\n",
      "25 ['CPD']\n",
      "26 ['Vehicle/BWC', 'Schroeder, Michelle L.']\n",
      "27 ['Officer Safety']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/yiminglin/Documents/Codebase/Pdf_reverse/')\n",
    "\n",
    "from model import model \n",
    "model_name = 'gpt4o'\n",
    "\n",
    "def result_gen_from_response(response):\n",
    "    if('|' not in response and 'no' in response.lower()):\n",
    "        return 0\n",
    "    l = response.split('|')\n",
    "    return len(l)+1\n",
    "\n",
    "def cluster_filtering(clusters):\n",
    "    #trick 1: drop singleton cluster \n",
    "    #for each remaining cluster, if half of phrases are not header, drop this cluster \n",
    "    instruction = 'The following list contains possibly keys and values extracted from a table. Return to me all the keys without explanation, and seperate each key by |. If no key is found, return NO.' \n",
    "    mp = {}\n",
    "    for cid, l in clusters.items():\n",
    "        context = \", \".join(l)\n",
    "        prompt = (instruction,context)\n",
    "        response = model(model_name,prompt)\n",
    "        key_num = result_gen_from_response(response)\n",
    "        if(key_num >= len(l)/2):\n",
    "            mp[cid] = l\n",
    "\n",
    "    return mp #mp is a new cluster after filtering by using LLM \n",
    "\n",
    "mp = cluster_filtering(remap)\n",
    "for k,v in mp.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 6, 10, 13, 19, 27]\n"
     ]
    }
   ],
   "source": [
    "def clustering_group(clusters):\n",
    "    c = {}\n",
    "    for cid, l in clusters.items():\n",
    "        c[cid] = len(l)\n",
    "    sc = dict(sorted(c.items(), key=lambda item: item[1]))\n",
    "    l = []\n",
    "    for k,v in sc.items():\n",
    "        l.append(v)\n",
    "    return l\n",
    "    \n",
    "\n",
    "l=clustering_group(remap)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation\n",
    "\n",
    " - totally relying on GPT to filter out clusters may introduce false negative, since one phrase can be both key and value semantically if no context is provided "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90, 204, 318, 334, 350, 366, 478, 494, 510, 655, 671, 687, 703, 814, 924]\n",
      "[6, 120, 232, 397, 543, 733, 843]\n"
     ]
    }
   ],
   "source": [
    "print(phrases['Officer'])\n",
    "print(phrases['Case Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 543 554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = [6, 120, 232, 397, 543, 733, 843]\n",
    "s2 = [18, 132, 244, 409, 554, 745, 855]\n",
    "\n",
    "perfect_match(s1,s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation \n",
    "- Perfect aligned is too strict. Relax it to be the delta distance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation\n",
    "- Phrases with a short vector is more likely to be perfectly aligned with the phrase with larger vector, introducing FP.\n",
    "\n",
    "Example 1: \n",
    "\n",
    "CPD [129, 406]\n",
    "\n",
    "Action Taken [92, 206, 320, 336, 352, 368, 480, 496, 512, 657, 673, 689, 705, 816, 926]\n",
    "\n",
    "Example 2:\n",
    "\n",
    "Fled Scene [44, 270]\n",
    "\n",
    "DOB [58, 172, 284, 448, 593, 625, 784, 894]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
